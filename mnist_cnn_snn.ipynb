{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing MNIST dataset and creating train and test loder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  #torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "  torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size_train,pin_memory = True, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  #torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "  torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, pin_memory = True,shuffle=True)\n",
    "\n",
    "#torchvision.transforms.Normalize(                                 (0.1307,), (0.3081,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.mnist = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(16, 20, kernel_size=5),\n",
    "            nn.BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 50),\n",
    "            nn.BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mnist(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_cpu = Net()\n",
    "network = network_cpu.cuda()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data.cuda())\n",
    "        loss = F.nll_loss(output, target.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), 'model.pth')\n",
    "            torch.save(optimizer.state_dict(), 'optimizer.pth')\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data.cuda())\n",
    "            test_loss += F.nll_loss(output, target.cuda(), size_average=False).item()\n",
    "            #test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            #correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            correct += pred.cpu().eq(target.data.view_as(pred.cpu())).sum()\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            test_losses.append(test_loss)\n",
    "            print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Network training\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Loding the weights of the network trained above\n",
    "## This is useful for those who don't want to train the network afresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_weights = torch.load('model.pth')\n",
    "\n",
    "saved_model = Net()\n",
    "saved_model = saved_model\n",
    "saved_model = saved_model.cuda()\n",
    "\n",
    "saved_model.load_state_dict(saved_weights)\n",
    "saved_model.eval()\n",
    "print(saved_model)\n",
    "\n",
    "#input_image = cv2.imread('temp_folder/img_137.jpg',0)/255#example_data[2][0]\n",
    "#input_tensor = torch.tensor(input_image[np.newaxis,np.newaxis,:,:],dtype=torch.float32)\n",
    "#print(input_tensor)\n",
    "#output = saved_model(input_tensor.cuda())\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = cv2.imread('temp_folder/img_137.jpg',0)/255#example_data[2][0]\n",
    "input_tensor = torch.tensor(input_image[np.newaxis,np.newaxis,:,:],dtype=torch.float32)\n",
    "#print(input_tensor)\n",
    "output = saved_model(input_tensor.cuda())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_layer_idx = [0,2,7]\n",
    "relu_layer_idx = [1,5,10,15,16]\n",
    "fc_layer_idx = [13,16]\n",
    "batch_norm2d_idx = [3,8]\n",
    "batch_norm1d_idx = [14]\n",
    "max_pool_idx = [4,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batch_norm2d(conv_layer_idx, bn2d_idx):\n",
    "    eps =1e-05\n",
    "    conv_weight = saved_weights['mnist.'+str(conv_layer_idx)+'.weight']\n",
    "    conv_bias = saved_weights['mnist.'+str(conv_layer_idx)+'.bias']\n",
    "    bn2d_gamma = saved_weights['mnist.'+str(bn2d_idx)+'.weight']\n",
    "    bn2d_beta = saved_weights['mnist.'+str(bn2d_idx)+'.bias']\n",
    "    \n",
    "    bn2d_mean = saved_weights['mnist.'+str(bn2d_idx)+'.running_mean']\n",
    "    bn2d_var = saved_weights['mnist.'+str(bn2d_idx)+'.running_var']\n",
    "    bn2d_var = torch.sqrt(bn2d_var + eps)\n",
    "    print(conv_weight.shape)\n",
    "\n",
    "    conv_weight = conv_weight.transpose(0,3)\n",
    "    print(conv_weight.shape)\n",
    "    #gamma = bn.weight\n",
    "    #beta = bn.bias\n",
    "    #mean = bn.running_mean\n",
    "    #var = bn.running_var\n",
    "    #eps =1e-05\n",
    "\n",
    "    #var_sqrt = torch.sqrt(var + eps)\n",
    "\n",
    "    #w = (self.weight * gamma.reshape(self.out_channels, 1, 1, 1)) / var_sqrt.reshape(self.out_channels, 1,1, 1)\n",
    "    #b = ((self.bias - mean) * gamma) / var_sqrt + beta\n",
    "\n",
    "    output_conv_weight = torch.mul(conv_weight, torch.div(bn2d_gamma, bn2d_var))\n",
    "    #print(output_conv_weight.shape)\n",
    "    output_conv_weight = output_conv_weight.transpose(0,3)\n",
    "    conv_weight = conv_weight.transpose(0,3)\n",
    "    output_conv_bias = torch.add(torch.mul((conv_bias-bn2d_mean), torch.div(bn2d_gamma,bn2d_var)),bn2d_beta)\n",
    "    return output_conv_weight, output_conv_bias#, #output_conv_weight, \n",
    "\n",
    "def merge_batch_norm1d(fc_layer_idx, bn1d_idx):\n",
    "    eps =1e-05\n",
    "\n",
    "    fc_weight = saved_weights['mnist.'+str(fc_layer_idx)+'.weight']\n",
    "    fc_bias = saved_weights['mnist.'+str(fc_layer_idx)+'.bias']\n",
    "    bn1d_gamma = saved_weights['mnist.'+str(bn1d_idx)+'.weight']\n",
    "    bn1d_beta = saved_weights['mnist.'+str(bn1d_idx)+'.bias']\n",
    "    bn1d_mean = saved_weights['mnist.'+str(bn1d_idx)+'.running_mean']\n",
    "    bn1d_var = saved_weights['mnist.'+str(bn1d_idx)+'.running_var']\n",
    "    bn1d_var = torch.sqrt(bn1d_var + eps)\n",
    "    fc_weight = fc_weight.transpose(0,1)\n",
    "    output_fc_weight = torch.mul(fc_weight, torch.div(bn1d_gamma, bn1d_var))\n",
    "    fc_weight = fc_weight.transpose(0,1)\n",
    "    output_fc_weight = output_fc_weight.transpose(0,1)\n",
    "    output_fc_bias = torch.add(torch.mul((fc_bias-bn1d_mean), torch.div(bn1d_gamma,bn1d_var)),bn1d_beta)\n",
    "    return output_fc_weight, output_fc_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_list_fn(layers_list,data_loader,model):\n",
    "    tensor_list = []\n",
    "    output_dict = {}\n",
    "    count =0\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        max_output_list =[]\n",
    "        x = data.cpu()\n",
    "        for idx,seq in enumerate(model):#.mnist):\n",
    "            x = seq(x)\n",
    "            if idx in layers_list:\n",
    "                max_output_list.append(x) #intermediate_output#(torch.flatten(x)))\n",
    "        #del data_cuda\n",
    "        #torch.cuda.empty_cache()\n",
    "        iter = 0\n",
    "        if count == 0:\n",
    "            tensor_list.append(data)\n",
    "        else:\n",
    "            tensor_list[iter] = torch.cat((tensor_list[iter],data),0)\n",
    "        iter+=1   \n",
    "        for idx in layers_list:\n",
    "            if count == 0:\n",
    "                tensor_list.append(max_output_list[iter-1])\n",
    "            else:\n",
    "                tensor_list[iter] = torch.cat((tensor_list[iter],max_output_list[iter-1]),0)\n",
    "            iter+=1\n",
    "        \n",
    "        count +=1\n",
    "    tensor_list[0] = torch.flatten(tensor_list[0]).detach().numpy()\n",
    "    output_dict['input'] = tensor_list[0]\n",
    "    iter =1\n",
    "    for idx in layers_list:\n",
    "        tensor_list[iter] = torch.flatten(tensor_list[iter]).detach().numpy()\n",
    "        output_dict[str(idx)] = tensor_list[iter]\n",
    "        iter+=1\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_list_fn_cuda(layers_list,data_loader,model):\n",
    "    tensor_list = []\n",
    "    output_dict = {}\n",
    "    count =0\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        max_output_list =[]\n",
    "        x = data.cuda()\n",
    "        for idx,seq in enumerate(model):#.mnist):\n",
    "            x = seq(x)\n",
    "            if idx in layers_list:\n",
    "                max_output_list.append(x.detach().cpu()) #intermediate_output#(torch.flatten(x)))\n",
    "        #del data_cuda\n",
    "        #torch.cuda.empty_cache()\n",
    "        iter = 0\n",
    "        if count == 0:\n",
    "            tensor_list.append(data)\n",
    "        else:\n",
    "            tensor_list[iter] = torch.cat((tensor_list[iter],data.cpu()),0)\n",
    "        iter+=1   \n",
    "        for idx in layers_list:\n",
    "            if count == 0:\n",
    "                tensor_list.append(max_output_list[iter-1])\n",
    "            else:\n",
    "                tensor_list[iter] = torch.cat((tensor_list[iter],max_output_list[iter-1]),0)\n",
    "            iter+=1\n",
    "        \n",
    "        count +=1\n",
    "    tensor_list[0] = torch.flatten(tensor_list[0]).detach().numpy()\n",
    "    output_dict['input'] = tensor_list[0]\n",
    "    iter =1\n",
    "    for idx in layers_list:\n",
    "        tensor_list[iter] = torch.flatten(tensor_list[iter]).detach().numpy()\n",
    "        output_dict[str(idx)] = tensor_list[iter]\n",
    "        iter+=1\n",
    "    \n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_output_dict = output_list_fn_cuda(relu_layer_idx,train_loader,saved_model.mnist.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print percentiles\n",
    "relu_layers = [1,5,10,15,16]\n",
    "percentile_99 = np.percentile(relu_output_dict['input'],99)\n",
    "percentile_99_9 = np.percentile(relu_output_dict['input'],99.9)\n",
    "percentile_99_99 = np.percentile(relu_output_dict['input'],99.99)\n",
    "percentile_100 = np.percentile(relu_output_dict['input'],100)\n",
    "print('99 percentile', percentile_99)\n",
    "print('99.9 percentile', percentile_99_9)\n",
    "print('99.99 percentile', percentile_99_99)\n",
    "print('100 percentile', percentile_100)\n",
    "percentile_dict = {}\n",
    "percentile_dict['layer_input_99'] = percentile_99\n",
    "percentile_dict['layer_input_99_9'] = percentile_99_9\n",
    "percentile_dict['layer_input_99_99'] = percentile_99_99\n",
    "percentile_dict['layer_input_100'] = percentile_100\n",
    "for idx in relu_layers:\n",
    "    percentile_99 = np.percentile(relu_output_dict[str(idx)],99)\n",
    "    percentile_99_9 = np.percentile(relu_output_dict[str(idx)],99.9)\n",
    "    percentile_99_99 = np.percentile(relu_output_dict[str(idx)],99.99)\n",
    "    percentile_100 = np.percentile(relu_output_dict[str(idx)],100)\n",
    "    percentile_dict['layer_'+str(idx)+'_99'] = percentile_99\n",
    "    percentile_dict['layer_'+str(idx)+'_99_9'] = percentile_99_9\n",
    "    percentile_dict['layer_'+str(idx)+'_99_99'] = percentile_99_99\n",
    "    percentile_dict['layer_'+str(idx)+'_100'] = percentile_100\n",
    "\n",
    "    print('99 percentile', percentile_99)\n",
    "    print('99.9 percentile', percentile_99_9)\n",
    "    print('99.99 percentile', percentile_99_99)\n",
    "\n",
    "    print('100 percentile', percentile_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step_size = relu_output_dict[0].cpu()/number_of_bins\n",
    "plt.scatter(np.arange(0,relu_output_dict[0].cpu(),step_size),relu_output_hist[0].cpu())\n",
    "plt.show()\n",
    "step_size = relu_output_dict[1].cpu()/number_of_bins\n",
    "plt.scatter(np.arange(0,relu_output_dict[1].cpu(),step_size),relu_output_hist[1].cpu())\n",
    "plt.show()\n",
    "step_size = relu_output_dict[2].cpu()/number_of_bins\n",
    "plt.scatter(np.arange(0,relu_output_dict[2].cpu(),step_size),relu_output_hist[2].cpu())\n",
    "plt.show()\n",
    "step_size = relu_output_dict[3].cpu()/number_of_bins\n",
    "plt.scatter(np.arange(0,relu_output_dict[3].cpu(),step_size),relu_output_hist[3].cpu())\n",
    "plt.show()\n",
    "step_size = relu_output_dict[4].cpu()/number_of_bins\n",
    "plt.scatter(np.arange(0,relu_output_dict[4].cpu(),step_size),relu_output_hist[4].cpu())\n",
    "plt.show()\n",
    "step_size = relu_output_dict[5].cpu()/number_of_bins\n",
    "plt.scatter(np.arange(0,relu_output_dict[5].cpu(),step_size),relu_output_hist[5].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weight_bias(weight,bias,l1_out,l2_out):\n",
    "    weight = torch.mul(weight,l1_out/l2_out)\n",
    "    bias = torch.div(bias,l2_out)\n",
    "    return weight,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weight = saved_weights['mnist.0.weight']\n",
    "conv1_bias = saved_weights['mnist.0.bias']\n",
    "\n",
    "conv2_weight, conv2_bias = merge_batch_norm2d(2,3)\n",
    "conv3_weight, conv3_bias = merge_batch_norm2d(7,8)\n",
    "fc1_weight,fc1_bias = merge_batch_norm1d(13,14)\n",
    "fc2_weight = saved_weights['mnist.16.weight']\n",
    "fc2_bias = saved_weights['mnist.16.bias']\n",
    "\n",
    "snn_conv1_weight,snn_conv1_bias = normalize_weight_bias(conv1_weight,conv1_bias,percentile_dict['layer_input_99_9'],percentile_dict['layer_1_99_9'])\n",
    "snn_conv2_weight,snn_conv2_bias = normalize_weight_bias(conv2_weight,conv2_bias,percentile_dict['layer_1_99_9'],percentile_dict['layer_5_99_9'])\n",
    "snn_conv3_weight,snn_conv3_bias = normalize_weight_bias(conv3_weight,conv3_bias,percentile_dict['layer_5_99_9'],percentile_dict['layer_10_99_9'])\n",
    "snn_fc1_weight,snn_fc1_bias = normalize_weight_bias(fc1_weight,fc1_bias,percentile_dict['layer_10_99_9'],percentile_dict['layer_15_99_9'])\n",
    "snn_fc2_weight,snn_fc2_bias = normalize_weight_bias(fc2_weight,fc2_bias,percentile_dict['layer_15_99_9'],percentile_dict['layer_16_99_9'])\n",
    "\n",
    "\n",
    "\n",
    "#print(snn_conv1_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_idx = [0,2,7]\n",
    "relu_layer_idx = [1,5,10,15,16]\n",
    "fc_layer_idx = [13,16]\n",
    "batch_norm2d_idx = [3,8]\n",
    "batch_norm1d_idx = [14]\n",
    "max_pool_idx = [4,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 2000\n",
    "test_batch_size = 1000\n",
    "snn_train_loader = torch.utils.data.DataLoader(\n",
    "  #torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "  torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=train_batch_size,pin_memory = False, shuffle=True)\n",
    "\n",
    "snn_test_loader = torch.utils.data.DataLoader(\n",
    "  #torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "  torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=test_batch_size, pin_memory = False,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size =0\n",
    "for batch_idx, (data, target) in enumerate(snn_train_loader):\n",
    "    train_size += data.shape[0]\n",
    "print(train_size)\n",
    "\n",
    "test_size =0\n",
    "for batch_idx, (data, target) in enumerate(snn_test_loader):\n",
    "    test_size += data.shape[0]\n",
    "print(test_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data gen: Generate data and analyze how many time steps on an average is needed for someone to confirm the output\n",
    "#spikenet_fc_1 = spiking_fc(1,snn_fc1_weight,snn_fc1_bias,1).cuda()\n",
    "#spikenet_fc_2 = spiking_fc(1,snn_fc2_weight,snn_fc2_bias,1).cuda()\n",
    "#spike_frame = torch.zeros_like(input_tensor)\n",
    "#spike_pot = torch.zeros_like(input_tensor)\n",
    "sp1_shape = snn_conv1_weight.shape\n",
    "spikenet_1 = nn.Conv2d(sp1_shape[0],sp1_shape[1],kernel_size=sp1_shape[2]).cuda()\n",
    "spikenet_1.weight = nn.Parameter(snn_conv1_weight)\n",
    "spikenet_1.bias = nn.Parameter(snn_conv1_bias)\n",
    "sp2_shape = snn_conv2_weight.shape\n",
    "spikenet_2 = nn.Conv2d(sp2_shape[0],sp2_shape[1],kernel_size=sp2_shape[2]).cuda()\n",
    "spikenet_2.weight = nn.Parameter(snn_conv2_weight)\n",
    "spikenet_2.bias = nn.Parameter(snn_conv2_bias)\n",
    "sp3_shape = snn_conv3_weight.shape\n",
    "spikenet_3 = nn.Conv2d(sp3_shape[0],sp3_shape[1],kernel_size=sp3_shape[2]).cuda()\n",
    "spikenet_3.weight = nn.Parameter(snn_conv3_weight)\n",
    "spikenet_3.bias = nn.Parameter(snn_conv3_bias)\n",
    "sp_fc1_shape = snn_fc1_weight.shape\n",
    "spikenet_fc_1 = nn.Linear(sp_fc1_shape[0],sp_fc1_shape[1]).cuda()\n",
    "spikenet_fc_1.weight = nn.Parameter(snn_fc1_weight)\n",
    "spikenet_fc_1.bias = nn.Parameter(snn_fc1_bias)\n",
    "sp_fc2_shape = snn_fc2_weight.shape\n",
    "spikenet_fc_2 = nn.Linear(sp_fc2_shape[0],sp_fc2_shape[1]).cuda()\n",
    "spikenet_fc_2.weight = nn.Parameter(snn_fc2_weight)\n",
    "spikenet_fc_2.bias = nn.Parameter(snn_fc2_bias)\n",
    "max_pool2 = nn.MaxPool2d(2, stride=2).cuda()\n",
    "max_pool3 = nn.MaxPool2d(2, stride=2).cuda()\n",
    "number_of_timesteps = 500 #1000\n",
    "train_output_expected = np.zeros((train_size,1))\n",
    "train_output_array = np.zeros((train_size,number_of_timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_over_time = np.zeros(train_output_array.shape[1])\n",
    "total_samples = train_output_array.shape[0]\n",
    "from scipy import stats\n",
    "for idx in range(train_output_array.shape[1]):\n",
    "    part_of_output = train_output_array[:,0:idx+1]\n",
    "    max_of_part = stats.mode(part_of_output,axis=1)[0]\n",
    "    #print(max_of_part)\n",
    "    percentage = np.sum(np.equal(max_of_part ,train_output_expected)*1.0)\n",
    "    #print(percentage)\n",
    "    accuracy_over_time[idx] = percentage*100/total_samples\n",
    "print(accuracy_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running SNN on train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_timesteps = 500\n",
    "test_output_expected = np.zeros((test_size,1))\n",
    "test_output_array = np.zeros((test_size,number_of_timesteps))\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(snn_train_loader):\n",
    "    #x = data np.zeros((1000,1000))\n",
    "    start = batch_idx*train_batch_size\n",
    "    end = batch_idx*train_batch_size + data.shape[0]\n",
    "    test_output_expected[start:end,0] = target.detach().numpy()\n",
    "    data = data.cuda()\n",
    "    #print(data.shape)\n",
    "    spike_pot = torch.zeros_like(data).detach()cuda()\n",
    "    sp1_out = torch.zeros((data.shape[0],8,26,26)).detach().cuda()\n",
    "    sp2_out = torch.zeros((data.shape[0],16,24,24)).detach().cuda()\n",
    "    sp3_out = torch.zeros((data.shape[0],20,8,8)).detach().cuda()\n",
    "    sp_fc1_out = torch.zeros((data.shape[0],50)).detach().cuda()\n",
    "    sp_fc2_out = torch.zeros((data.shape[0],10)).detach().cuda()\n",
    "\n",
    "    \n",
    "    for i in range(number_of_timesteps):\n",
    "        print(i)\n",
    "        first_frame = True if i ==0 else False\n",
    "        #x = spike_frame_mnist.reset_by_subtraction(input_tensor,first_frame)\n",
    "            \n",
    "        #spike_pot = torch.add(spike_pot, data)\n",
    "        spike_pot.add_(data)\n",
    "\n",
    "        spike_frame = torch.gt(spike_pot,1.0)*1.0\n",
    "        spike_pot.sub_(spike_frame)\n",
    "        sp1_out.add_(spikenet_1(spike_frame))\n",
    "        sp2_in = torch.gt(sp1_out,1.0)*1.0\n",
    "        sp1_out.sub_(sp2_in)\n",
    "        sp2_out.add_(spikenet_2(sp2_in))\n",
    "        sp3_in = torch.gt(sp2_out,1.0)*1.0\n",
    "        sp2_out.sub_(sp3_in)\n",
    "        sp3_in_red = max_pool2(sp3_in)\n",
    "        sp3_out.add_(spikenet_3(sp3_in_red))\n",
    "        sp4_in = torch.gt(sp3_out,1.0)*1.0\n",
    "        sp3_out.sub_(sp4_in)\n",
    "        sp4_in_red = max_pool3(sp4_in)\n",
    "        sp4_in_red_flat = torch.flatten(sp4_in_red,start_dim=1)\n",
    "        sp_fc1_out.add_(spikenet_fc_1(sp4_in_red_flat))\n",
    "        sp_fc2_in = torch.gt(sp_fc1_out,1.0)*1.0\n",
    "        sp_fc1_out.sub_(sp_fc2_in)\n",
    "        sp_fc2_out.add_(spikenet_fc_2(sp_fc2_in))\n",
    "        sof_pot = F.softmax(sp_fc2_out)\n",
    "        max_numbers = torch.argmax(sof_pot,dim=1)\n",
    "        test_output_array[start:end,i] = max_numbers.cpu().detach().numpy()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running SNN on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAM PLEASE LOOK AT THIS CODE\n",
    "\n",
    "number_of_timesteps = 400\n",
    "\n",
    "test_output_expected = np.zeros((test_size,1))\n",
    "test_output_array = np.zeros((test_size,number_of_timesteps))\n",
    "for batch_idx, (data, target) in enumerate(snn_test_loader):\n",
    "    start = batch_idx*train_batch_size\n",
    "    end = batch_idx*train_batch_size + data.shape[0]\n",
    "    test_output_expected[start:end,0] = target.detach().numpy()\n",
    "    data = data.cuda()\n",
    "    spike_pot = torch.zeros_like(data).detach().cuda()\n",
    "    sp1_np = np.zeros((data.shape[0],8,26,26))\n",
    "    sp1_out = torch.tensor(sp1_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp2_np = np.zeros((data.shape[0],16,24,24))\n",
    "    sp2_out = torch.tensor(sp2_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp3_np = np.zeros((data.shape[0],20,8,8))\n",
    "    sp3_out = torch.tensor(sp3_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp_fc1_np = np.zeros((data.shape[0],50))\n",
    "    sp_fc1_out = torch.tensor(sp_fc1_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp_fc2_np = np.zeros((data.shape[0],10))\n",
    "    sp_fc2_out = torch.tensor(sp_fc2_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    \n",
    "    for i in range(number_of_timesteps):\n",
    "        print(i)\n",
    "        first_frame = True if i ==0 else False\n",
    "        spike_pot.add_(data)\n",
    "\n",
    "        spike_frame = torch.gt(spike_pot,1.0)*1.0 #F.threshold_(spike_pot,1,0).sign() #\n",
    "        spike_pot.sub_(spike_frame)\n",
    "        sp1_out.add_(spikenet_1(spike_frame).detach())\n",
    "        sp2_in = torch.gt(sp1_out,1.0)*1.0 #F.threshold_(sp1_out, 1, 0) #\n",
    "        sp1_out.sub_(sp2_in)\n",
    "        sp2_out.add_(spikenet_2(sp2_in).detach())\n",
    "        sp3_in = torch.gt(sp2_out,1.0)*1.0 #F.threshold_(sp2_out, 1, 0).sign() # \n",
    "        sp2_out.sub_(sp3_in)\n",
    "        sp3_in_red = max_pool2(sp3_in)\n",
    "        sp3_out.add_(spikenet_3(sp3_in_red).detach())\n",
    "        sp4_in = torch.gt(sp3_out,1.0)*1.0 #F.threshold_(sp3_out, 1, 0).sign() #\n",
    "        sp3_out.sub_(sp4_in)\n",
    "        sp4_in_red = max_pool3(sp4_in)\n",
    "        sp4_in_red_flat = torch.flatten(sp4_in_red,start_dim=1)\n",
    "        sp_fc1_out.add_(spikenet_fc_1(sp4_in_red_flat).detach())\n",
    "        sp_fc2_in = torch.gt(sp_fc1_out,1.0)*1.0 #F.threshold_(sp_fc1_out, 1, 0).sign() #\n",
    "        sp_fc1_out.sub_(sp_fc2_in)\n",
    "        sp_fc2_out.add_(spikenet_fc_2(sp_fc2_in).detach())\n",
    "        sof_pot = F.softmax(sp_fc2_out).detach()\n",
    "        max_numbers = torch.argmax(sof_pot,dim=1)\n",
    "        test_output_array[start:end,i] = max_numbers.cpu().detach().numpy()\n",
    "        print(torch.cuda.memory_allocated(device=0))\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_over_time = np.zeros(test_output_array.shape[1])\n",
    "total_samples = test_output_array.shape[0]\n",
    "from scipy import stats\n",
    "for idx in range(test_output_array.shape[1]):\n",
    "    part_of_output = test_output_array[:,0:idx+1]\n",
    "    max_of_part = stats.mode(part_of_output,axis=1)[0]\n",
    "    #print(max_of_part)\n",
    "    percentage = np.sum(np.equal(max_of_part ,test_output_expected)*1.0)\n",
    "    #print(percentage)\n",
    "    accuracy_over_time[idx] = percentage*100/total_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output_array[199])\n",
    "print(train_output_array.shape)\n",
    "print(train_output_expected.shape)\n",
    "print(test_output_array.shape)\n",
    "print(test_output_expected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class compute_analysis():\n",
    "    def __init__(self,inp_ch, out_ch, padding='valid', filter_size=(3,3)):\n",
    "        #super.init(compute_analysis,self).__init__()\n",
    "        self.inp_ch = inp_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.filter_size = filter_size\n",
    "        self.padding = padding\n",
    "        self.total_number_of_conv_ops = 0\n",
    "        self.single_conv_ops =0 \n",
    "        self.shape = None\n",
    "        self.output_shape = np.zeros(2)\n",
    "        self.first_ifmap = 1\n",
    "        self.ifmap_sparsity_list = [] #torch.zeros(1)\n",
    "        self.number_of_zero_ifmaps = 0\n",
    "        self.number_of_nonzero_addtions =0\n",
    "        self.layer_dict ={}\n",
    "        self.sparsity_tensor = None\n",
    "        self.conv_counter = nn.Conv2d(inp_ch,out_ch,kernel_size=filter_size).cuda()\n",
    "        self.conv_weight = torch.zeros((out_ch,inp_ch,*filter_size),dtype= torch.float32)+1.0\n",
    "        self.conv_bias = torch.zeros(out_ch)\n",
    "\n",
    "        self.conv_counter.weight = nn.Parameter(self.conv_weight.cuda())\n",
    "        self.conv_counter.bias = nn.Parameter(self.conv_bias.cuda())\n",
    "        \n",
    "    ## This will measure sparsity over input images    \n",
    "    def crude_conv_analysis(self,input_frame,first_frame):\n",
    "        if first_frame == True:\n",
    "            self.shape = input_frame.shape\n",
    "            shape = self.shape\n",
    "            number_of_inp_pix = shape[0]*shape[1]*shape[2]*shape[3]\n",
    "            if self.padding == 'valid':\n",
    "                self.output_shape[0] = int(shape[2]-self.filter_size[0]+1)\n",
    "                self.output_shape[1] = int(shape[3]-self.filter_size[1]+1)\n",
    "            else:\n",
    "                self.output_shape[0] = int(shape[2])\n",
    "                self.output_shape[1] = int(shape[3])\n",
    "            \n",
    "            self.total_number_of_conv_ops = shape[0]*(self.output_shape[0])*(self.output_shape[1])*self.out_ch*self.filter_size[0]*self.filter_size[1]*shape[1]#self.inp_ch\n",
    "            self.single_conv_ops = (self.output_shape[0])*(self.output_shape[1])*self.out_ch*self.filter_size[0]*self.filter_size[1]*self.inp_ch\n",
    "            number_of_mult_in_conv_per_op = self.filter_size[0]*self.filter_size[1]*self.inp_ch\n",
    "            for i in range(shape[0]):\n",
    "                for j in range(shape[1]):\n",
    "                    for id1 in range(int(self.output_shape[0])):\n",
    "                        for id2 in range(int(self.output_shape[1])):\n",
    "                            if self.first_ifmap == 1:\n",
    "                                number_of_on_fields = torch.sum(input_frame[i,j,id1:id1+self.filter_size[0],id2:id2+self.filter_size[1]])\n",
    "                                self.number_of_nonzero_addtions += number_of_on_fields*self.out_ch\n",
    "                                if number_of_on_fields ==0:\n",
    "                                    self.number_of_zero_ifmaps+=1\n",
    "                                #print('before',self.ifmap_sparsity_list,torch.div(number_of_on_fields,number_of_mult_in_conv_per_op))\n",
    "                                self.ifmap_sparsity_list.append(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op).detach().numpy().item(0))\n",
    "                                #print('after',self.ifmap_sparsity_list)\n",
    "\n",
    "                                #self.ifmap_sparsity_list.append(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op))\n",
    "                                #print(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op))#self.ifmap_sparsity_list)\n",
    "                                self.first_ifmap = 0\n",
    "                            else:\n",
    "                                number_of_on_fields = torch.sum(input_frame[i,j,id1:id1+self.filter_size[0],id2:id2+self.filter_size[1]])\n",
    "                                self.number_of_nonzero_addtions += number_of_on_fields*self.out_ch\n",
    "                                if number_of_on_fields ==0:\n",
    "                                    self.number_of_zero_ifmaps+=1\n",
    "                                #print(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op))#self.ifmap_sparsity_list)\n",
    "                                #print('before',self.ifmap_sparsity_list)\n",
    "\n",
    "                                self.ifmap_sparsity_list.append(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op).detach().numpy().item(0))\n",
    "                                #print('after',self.ifmap_sparsity_list)\n",
    "\n",
    "                                #self.ifmap_sparsity_list = torch.cat((self.ifmap_sparsity_list[0],torch.div(number_of_on_fields,number_of_mult_in_conv_per_op)),0)\n",
    "        \n",
    "        else:\n",
    "            self.shape = input_frame.shape\n",
    "            shape = self.shape\n",
    "            number_of_inp_pix = shape[0]*shape[1]*shape[2]*shape[3]\n",
    "\n",
    "            self.total_number_of_conv_ops += shape[0]*(self.output_shape[0])*(self.output_shape[1])*self.out_ch*self.filter_size[0]*self.filter_size[1]*shape[1]#self.inp_ch\n",
    "            number_of_mult_in_conv_per_op = self.filter_size[0]*self.filter_size[1]*self.inp_ch\n",
    "            for i in range(shape[0]):\n",
    "                for j in range(shape[1]):\n",
    "                    for id1 in range(int(self.output_shape[0])):\n",
    "                        for id2 in range(int(self.output_shape[1])):\n",
    "                            number_of_on_fields = torch.sum(input_frame[i,j,id1:id1+self.filter_size[0],id2:id2+self.filter_size[1]])\n",
    "                            self.number_of_nonzero_addtions += number_of_on_fields*self.out_ch\n",
    "                            if number_of_on_fields ==0:\n",
    "                                self.number_of_zero_ifmaps+=1\n",
    "                            #print(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op))#self.ifmap_sparsity_list)\n",
    "                            #self.ifmap_sparsity_list = torch.cat((self.ifmap_sparsity_list,torch.div(number_of_on_fields,number_of_mult_in_conv_per_op)),0)\n",
    "                            self.ifmap_sparsity_list.append(torch.div(number_of_on_fields,number_of_mult_in_conv_per_op).detach().numpy().item(0))\n",
    "\n",
    "                            #self.ifmap_sparsity_list = torch.cat((self.ifmap_sparsity_list[0],torch.div(number_of_on_fields,number_of_mult_in_conv_per_op)),0)\n",
    "                            \n",
    "        \n",
    "\n",
    "            \n",
    "        return 0\n",
    "    def conv_analysis(self,input_frame,first_frame):\n",
    "        if first_frame == True:\n",
    "            self.shape = input_frame.shape\n",
    "            shape = self.shape\n",
    "            number_of_inp_pix = shape[0]*shape[1]*shape[2]*shape[3]\n",
    "            if self.padding == 'valid':\n",
    "                self.output_shape[0] = int(shape[2]-self.filter_size[0]+1)\n",
    "                self.output_shape[1] = int(shape[3]-self.filter_size[1]+1)\n",
    "            else:\n",
    "                self.output_shape[0] = int(shape[2])\n",
    "                self.output_shape[1] = int(shape[3])\n",
    "\n",
    "            self.total_number_of_conv_ops = shape[0]*(self.output_shape[0])*(self.output_shape[1])*self.out_ch*self.filter_size[0]*self.filter_size[1]*shape[1]#self.inp_ch\n",
    "            self.single_conv_ops = (self.output_shape[0])*(self.output_shape[1])*self.out_ch*self.filter_size[0]*self.filter_size[1]*self.inp_ch\n",
    "            number_of_mult_in_conv_per_op = self.filter_size[0]*self.filter_size[1]*self.inp_ch*self.out_ch\n",
    "            #self.hist_bins = np.arange(number_of_mult_in_conv_per_op+1)\n",
    "            number_of_on_fields = self.conv_counter(input_frame).detach().cpu()\n",
    "            self.sparsity_tensor= torch.histc(number_of_on_fields,bins = number_of_mult_in_conv_per_op+1,max = number_of_mult_in_conv_per_op,min=0)\n",
    "            self.number_of_nonzero_addtions += torch.sum(number_of_on_fields).detach().item()\n",
    "            self.number_of_zero_ifmaps += torch.sum(torch.eq(number_of_on_fields,0)*1.0).detach().item()\n",
    "            #self.sparsity_tensor = number_of_on_fields\n",
    "            #self.sparsity_tensor = torch.div(number_of_on_fields,number_of_mult_in_conv_per_op).detach()\n",
    "        \n",
    "        else:\n",
    "            self.shape = input_frame.shape\n",
    "            shape = self.shape\n",
    "            number_of_inp_pix = shape[0]*shape[1]*shape[2]*shape[3]\n",
    "\n",
    "            self.total_number_of_conv_ops += shape[0]*(self.output_shape[0])*(self.output_shape[1])*self.out_ch*self.filter_size[0]*self.filter_size[1]*shape[1]#self.inp_ch\n",
    "            number_of_mult_in_conv_per_op = self.filter_size[0]*self.filter_size[1]*self.inp_ch*self.out_ch\n",
    "            number_of_on_fields = self.conv_counter(input_frame).detach().cpu()\n",
    "            self.number_of_nonzero_addtions += torch.sum(number_of_on_fields).detach().item()\n",
    "            self.number_of_zero_ifmaps += torch.sum(torch.eq(number_of_on_fields,0)*1.0).detach().item()\n",
    "            self.sparsity_tensor.add_(torch.histc(number_of_on_fields,bins = number_of_mult_in_conv_per_op+1,max = number_of_mult_in_conv_per_op,min=0))\n",
    "\n",
    "            #self.sparsity_tensor = torch.cat((self.sparsity_tensor,number_of_on_fields),0)\n",
    "            #self.sparsity_tensor = torch.cat((self.sparsity_tensor,torch.div(number_of_on_fields,number_of_mult_in_conv_per_op).detach()),0)\n",
    "\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    def summary(self):\n",
    "        self.layer_dict  = {'total_pure_ann_ops':self.total_number_of_conv_ops, 'single_ann_ops':self.single_conv_ops, 'ifmap_sparsity_list':self.ifmap_sparsity_list,'number_of_zero_ifmaps':self.number_of_zero_ifmaps,'total_nonzero_ops':self.number_of_nonzero_addtions,'sparsity_tensor':torch.flatten(self.sparsity_tensor)}\n",
    "        return self.layer_dict\n",
    "        \n",
    "        \n",
    "    def fc_analysis(self,input_frame):\n",
    "        return 0\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_timesteps = 200\n",
    "conv1_analysis = compute_analysis(1, 8)\n",
    "conv2_analysis = compute_analysis(8, 16)\n",
    "conv3_analysis = compute_analysis(16, 20,(5,5))\n",
    "test_output_expected = np.zeros((test_size,1))\n",
    "test_output_array = np.zeros((test_size,number_of_timesteps))\n",
    "for batch_idx, (data, target) in enumerate(snn_test_loader):\n",
    "    start = batch_idx*train_batch_size\n",
    "    end = batch_idx*train_batch_size + data.shape[0]\n",
    "    data = data.cuda()\n",
    "    \n",
    "    spike_pot = torch.zeros_like(data).detach().cuda()\n",
    "    sp1_np = np.zeros((data.shape[0],8,26,26))\n",
    "    sp1_out = torch.tensor(sp1_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp2_np = np.zeros((data.shape[0],16,24,24))\n",
    "    sp2_out = torch.tensor(sp2_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp3_np = np.zeros((data.shape[0],20,8,8))\n",
    "    sp3_out = torch.tensor(sp3_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp_fc1_np = np.zeros((data.shape[0],50))\n",
    "    sp_fc1_out = torch.tensor(sp_fc1_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    sp_fc2_np = np.zeros((data.shape[0],10))\n",
    "    sp_fc2_out = torch.tensor(sp_fc2_np, requires_grad=False, dtype=torch.float32).cuda()\n",
    "    \n",
    "    for i in range(number_of_timesteps):\n",
    "        #print(i)\n",
    "        first_frame = True if i ==0 else False\n",
    "        spike_pot.add_(data)\n",
    "\n",
    "        spike_frame = torch.gt(spike_pot,1.0)*1.0 #F.threshold_(spike_pot,1,0).sign() #\n",
    "        spike_pot.sub_(spike_frame)\n",
    "        conv1_analysis.conv_analysis(spike_frame,first_frame)\n",
    "        sp1_out.add_(spikenet_1(spike_frame).detach())\n",
    "        sp2_in = torch.gt(sp1_out,1.0)*1.0 #F.threshold_(sp1_out, 1, 0) #\n",
    "        sp1_out.sub_(sp2_in)\n",
    "        conv2_analysis.conv_analysis(sp2_in,first_frame)\n",
    "\n",
    "        sp2_out.add_(spikenet_2(sp2_in).detach())\n",
    "        sp3_in = torch.gt(sp2_out,1.0)*1.0 #F.threshold_(sp2_out, 1, 0).sign() # \n",
    "        sp2_out.sub_(sp3_in)\n",
    "        conv3_analysis.conv_analysis(sp3_in,first_frame)\n",
    "\n",
    "        sp3_in_red = max_pool2(sp3_in)\n",
    "        sp3_out.add_(spikenet_3(sp3_in_red).detach())\n",
    "        sp4_in = torch.gt(sp3_out,1.0)*1.0 #F.threshold_(sp3_out, 1, 0).sign() #\n",
    "        sp3_out.sub_(sp4_in)\n",
    "        sp4_in_red = max_pool3(sp4_in)\n",
    "        sp4_in_red_flat = torch.flatten(sp4_in_red,start_dim=1)\n",
    "        sp_fc1_out.add_(spikenet_fc_1(sp4_in_red_flat).detach())\n",
    "        sp_fc2_in = torch.gt(sp_fc1_out,1.0)*1.0 #F.threshold_(sp_fc1_out, 1, 0).sign() #\n",
    "        sp_fc1_out.sub_(sp_fc2_in)\n",
    "        sp_fc2_out.add_(spikenet_fc_2(sp_fc2_in).detach())\n",
    "        sof_pot = F.softmax(sp_fc2_out).detach()\n",
    "        max_numbers = torch.argmax(sof_pot,dim=1)\n",
    "        print(torch.cuda.memory_allocated(device=0))\n",
    "        torch.cuda.empty_cache()\n",
    "    if(batch_idx==5):\n",
    "        break\n",
    "    else:\n",
    "        print('batch_id', batch_idx)\n",
    "\n",
    "\n",
    "\n",
    "print(conv1_analysis.summary())  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda9p2",
   "language": "python",
   "name": "pytorch_cuda9p2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
